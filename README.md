# OpenVINO-Glossary

A glossary of terms used in the Intel® Distribution of OpenVINO™ toolkit.

**Instructions**
This file is in simple Git-flavored Markdown (.md) language.  We suggest copying existing lines and modifying them as needed.
Add a term you'd like to see defined, or add a definition to a term listed below.  

**Glossary Goals**
This glossary will help clarify terms we commonly use in the Intel® distribution of OpenVINO and will be shared both internally and eventually with our customers.  Our goal is to complete this glossary by March 13, 2020 in preparation for our first set of core documentation to be localized to the PRC in simple Chinese.

Any terms we fail to define, the localization vendor will have to define for themselves.  **We want to avoid forcing them to define terms for themselves.**

**NOTE: Please edit this file directly.  DO NOT USE A BRANCH/PULL REQUEST.**

**Accelerator:** Computer hardware specially designed to perform some functions more efficiently than is possible in software running on a general-purpose CPU. 

**Demo / Demo Application:** Demonstration OpenVINO applications that focus on executing a particular Deep Learning capability such as object recognition application, face detection, age detection, etc.  Demo applications provide robust application templates to support developers in implementing specific deep learning scenarios. They may also involve more complex processing pipelines that gather analysis from several models that run inference simultaneously. For example, concurrently detecting a person in a video stream and detecting attributes such as age, gender and/or emotions.

**Inference Engine:** The software libraries that run inference against the Intermediate Representation (Optimized Model) to produce inference results.

**Intermediate Representation (IR):** Is the output of the Model Optimizer. A model converted to a format that has been optimized for Intel architecture and is usable by the Inference Engine.

**Model:** Define here.

**Model Optimizer:** Optimizes models for Intel® architecture, converting models into a format compatible with the Inference Engine. This format is called an Intemediate Representation (IR).

**Reference Implementation:** Full demonstration implementations that make use of multiple Deep Learning capabilities in a use case focused on a particular domain. For example, object recognition and face detection for a Retail use case. Designed to demonstrate a complete IoT solution, Reference Implementation documentation provides IoT Developers with information on tools, code samples, applications and the required resources so they can build and deploy their own IoT projects.

**Reference Solution:** Designed to demonstrate an end to end IoT solution that is commercially ready.  Reference Soutions provide IoT Developers with source code, requirements, design, test documentation, demo and the required resources that have been integrated with Intel hardware and software platforms and can be immediately downloadable, so they can further customize and deploy their own IoT projects on it. 

**Samples / Sample Code:** Small snippets of example code that can be used in an application. Shows how to utilize specific OpenVino capabilities within an application. Sample code assits developers in executing specific tasks such as loading a model, running inference, how to query specific device capabilities, or processing output results i.e. classification and/or detection.  Samples and Sample Code are often used interchangeably in this context.  

**Sample Application:** Define here.

