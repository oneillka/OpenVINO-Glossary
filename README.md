# OpenVINO-Glossary

A glossary of terms used in the Intel® Distribution of OpenVINO™ toolkit.

**Instructions:**
This file is in simple Git-flavored Markdown (.md) language.  We suggest copying existing lines and modifying them as needed.
Add a term you'd like to see defined, or add a definition to a term listed below.  Our goal is to complete this glossary by February 28, 2020 in preparation for our first set of documentation to be localized to the PRC in simple Chinese.

**NOTE: Please edit this file directly.  DO NOT USE A BRANCH/PULL REQUEST.**

**Accelerator:** Computer hardware specially designed to perform some functions more efficiently than is possible in software running on a general-purpose CPU. 

**Demo:** Define here.

**Inference Engine:** The software libraries that run inference against the Intermediate Representation (Optimized Model) to produce inference results.

**Intermediate Representation (IR):** Is the output of the Model Optimizer. A model converted to a format that has been optimized for Intel architecture and is usable by the Inference Engine.

**Model:** Define here.

**Model Optimizer:** Optimizes models for Intel® architecture, converting models into a format compatible with the Inference Engine. This format is called an Intemediate Representation (IR).

**Sample Application:** Define here.

